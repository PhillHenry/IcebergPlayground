<!DOCTYPE html>
<html>
<head>
<style type="text/css">
body {background-color: black;}
pre {
	font-weight: normal;
	color: #bbb;
	white-space: -moz-pre-wrap;
	white-space: -o-pre-wrap;
	white-space: -pre-wrap;
	white-space: pre-wrap;
	word-wrap: break-word;
	overflow-wrap: break-word;
}
b {font-weight: normal}
b.BOLD {color: #fff}
b.ITA {font-style: italic}
b.UND {text-decoration: underline}
b.STR {text-decoration: line-through}
b.UNDSTR {text-decoration: underline line-through}
b.BLK {color: #000000}
b.RED {color: #aa0000}
b.GRN {color: #00aa00}
b.YEL {color: #aa5500}
b.BLU {color: #0000aa}
b.MAG {color: #aa00aa}
b.CYN {color: #00aaaa}
b.WHI {color: #aaaaaa}
b.HIK {color: #555555}
b.HIR {color: #ff5555}
b.HIG {color: #55ff55}
b.HIY {color: #ffff55}
b.HIB {color: #5555ff}
b.HIM {color: #ff55ff}
b.HIC {color: #55ffff}
b.HIW {color: #ffffff}
b.BBLK {background-color: #000000}
b.BRED {background-color: #aa0000}
b.BGRN {background-color: #00aa00}
b.BYEL {background-color: #aa5500}
b.BBLU {background-color: #0000aa}
b.BMAG {background-color: #aa00aa}
b.BCYN {background-color: #00aaaa}
b.BWHI {background-color: #aaaaaa}
</style>
</head>
<body>
<pre>Discovery starting.
Discovery completed in 94 milliseconds.
Run starting. Expected test count is: 13
IcebergCRUDSpec:
A dataset to CRUD
- should create the appropriate Iceberg files
  + Given data
			Datum(0,label_0,0)
			Datum(1,label_1,1)
			Datum(2,label_2,2)
			... 
  + When writing to table 'IcebergCRUDSpec' 
  + Then reading the table back yields the same data 
- should support updates with 'update IcebergCRUDSpec set label='ipse locum''
  + Given SQL 'update IcebergCRUDSpec set label='ipse locum' 
  + When we execute it 
  + Then all rows are updated 
  + And look like:
			Datum(10,ipse locum,0)
			Datum(11,ipse locum,1)
			Datum(12,ipse locum,2)
			... 
- should updates the schema
  + Given SQL 'ALTER TABLE IcebergCRUDSpec ADD COLUMNS (new_string string comment 'new_string docs') 
  + When we execute it 
  + Then all rows are updated 
  + And look like:
			[10,ipse locum,0,null]
			[11,ipse locum,1,null]
			[12,ipse locum,2,null]
			... 
- should when vacuumed, have old files removed !!! IGNORED !!!
CachingSpec:
A dataset to CRUD
- should create the appropriate Iceberg files
  + Given data
			Datum(0,label_0,0)
			Datum(1,label_1,1)
			Datum(2,label_2,2)
			... 
  + When we cache one Dataset and then append more data to the same table 
  + Then reading via a new Dataset reference shows the appended data 
  + And the old, cached reference still sees the old snapshot of data 
ConcurrentWriteSpec:
Concurrent writes
- should cause one transaction to fail
  + Given two transactions trying to write data
			Datum(0,label_0,0)
			Datum(1,label_1,1)
			Datum(2,label_2,2)
			... 
  + When both run at the same time 
  + Then one fails with exception org.apache.iceberg.exceptions.CommitFailedException: Version 1 already exists: /tmp/SparkForTesting13151680448113525139/ConcurrentWriteSpec/metadata/v1.metadata.json 
  + And one succeeds 
MergeOnReadSpec:
A merge-on-read table
- should create no new files for merge-on-read
  + Given SQL:
<b class=BLU>'CREATE TABLE mor_table (id int,
label String,
partitionKey long) TBLPROPERTIES (
    'format-version' = '2',
    'write.delete.mode'='merge-on-read',
    'write.update.mode'='merge-on-read',
    'write.merge.mode'='merge-on-read'
) PARTITIONED BY (partitionKey); </b> 
  + When we execute it 
  + Then there is an Iceberg table, /tmp/SparkForTesting13151680448113525139/mor_table 
- should insert creates new files for merge-on-read
  + Given SQL:
INSERT INTO TABLE mor_table (id,
label,
partitionKey) VALUES (0, 'label_0', 0),
(1, 'label_1', 1),
(2, 'label_2', 2),
(3, 'label_3', 3),
(4, 'label_4', 4),
(5, 'label_5', 0),
(6, 'label_6', 1),
(7, 'label_7', 2),
(8, 'label_8', 3),
(9, 'label_9', 4),
(10, 'label_10', 0),
(11, 'label_11', 1),
(12, 'label_12', 2),
(13, 'label_13', 3),
(14, 'label_14', 4),
(15, 'label_15', 0),
(16, 'label_16', 1),
(17, 'label_17', 2),
(18, 'label_18', 3),
(19, 'label_19', 4) 
  + When we execute it 
  + Then there are now 10 data files:
<b class=BLU>/partitionKey=0/.00005-220-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet.crc
</b><b class=BLU>/partitionKey=0/00005-220-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet
</b><b class=BLU>/partitionKey=1/.00069-221-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet.crc
</b><b class=BLU>/partitionKey=1/00069-221-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet
</b><b class=BLU>/partitionKey=2/.00128-223-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet.crc
</b><b class=BLU>/partitionKey=2/00128-223-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet
</b><b class=BLU>/partitionKey=3/.00107-222-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet.crc
</b><b class=BLU>/partitionKey=3/00107-222-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet
</b><b class=BLU>/partitionKey=4/.00140-224-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet.crc
</b><b class=BLU>/partitionKey=4/00140-224-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet</b> 
  + And the table contains:
<b class=BLU>Datum(0,label_0,0)
Datum(1,label_1,1)
Datum(2,label_2,2)
Datum(3,label_3,3)
Datum(4,label_4,4)
Datum(5,label_5,0)
Datum(6,label_6,1)
Datum(7,label_7,2)
Datum(8,label_8,3)
Datum(9,label_9,4)
Datum(10,label_10,0)
Datum(11,label_11,1)
Datum(12,label_12,2)
Datum(13,label_13,3)
Datum(14,label_14,4)
Datum(15,label_15,0)
Datum(16,label_16,1)
Datum(17,label_17,2)
Datum(18,label_18,3)
Datum(19,label_19,4)</b> 
- should update creates no new files for merge-on-read
  + Given SQL:
UPDATE mor_table SET label='label_1X' WHERE id=1 
  + When we execute it 
  + Then there are now 14 data files:
<b class=GRN>/partitionKey=0/.00005-220-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet.crc
</b><b class=GRN>/partitionKey=0/00005-220-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet
</b><b class=GRN>/partitionKey=1/.00069-221-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet.crc
</b><b class=BLU>/partitionKey=1/.00089-422-de4dcfc2-0070-4e9d-a0d2-1c5aaa8255bd-00001-deletes.parquet.crc
</b><b class=BLU>/partitionKey=1/.00089-422-de4dcfc2-0070-4e9d-a0d2-1c5aaa8255bd-00001.parquet.crc
</b><b class=GRN>/partitionKey=1/00069-221-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet
</b><b class=BLU>/partitionKey=1/00089-422-de4dcfc2-0070-4e9d-a0d2-1c5aaa8255bd-00001-deletes.parquet
</b><b class=BLU>/partitionKey=1/00089-422-de4dcfc2-0070-4e9d-a0d2-1c5aaa8255bd-00001.parquet
</b><b class=GRN>/partitionKey=2/.00128-223-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet.crc
</b><b class=GRN>/partitionKey=2/00128-223-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet
</b><b class=GRN>/partitionKey=3/.00107-222-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet.crc
</b><b class=GRN>/partitionKey=3/00107-222-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet
</b><b class=GRN>/partitionKey=4/.00140-224-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet.crc
</b><b class=GRN>/partitionKey=4/00140-224-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet</b> 
  + And the deleted files are:
<b class=RED>bbda2792-00001.parquet.crc
bda2792-00001.parquet
bbda2792-00001.parquet.crc
bda2792-00001.parquet
bbda2792-00001.parquet.crc
bda2792-00001.parquet
bbda2792-00001.parquet.crc
bda2792-00001.parquet
bbda2792-00001.parquet.crc
bda2792-00001.parquet</b> 
  + And the table contains:
<b class=BLU>Datum(0,label_0,0)
Datum(1,label_1X,1)
Datum(2,label_2,2)
Datum(3,label_3,3)
Datum(4,label_4,4)
Datum(5,label_5,0)
Datum(6,label_6,1)
Datum(7,label_7,2)
Datum(8,label_8,3)
Datum(9,label_9,4)
Datum(10,label_10,0)
Datum(11,label_11,1)
Datum(12,label_12,2)
Datum(13,label_13,3)
Datum(14,label_14,4)
Datum(15,label_15,0)
Datum(16,label_16,1)
Datum(17,label_17,2)
Datum(18,label_18,3)
Datum(19,label_19,4)</b> 
  + And  the '*-deletes.parquet' file /partitionKey=1/00089-422-de4dcfc2-0070-4e9d-a0d2-1c5aaa8255bd-00001-deletes.parquet contains a reference to /partitionKey=1/00069-221-e8766c90-a758-457e-914b-6f4dbbda2792-00001.parquet which contains:
<b class=BLU>Datum(1,label_1,1)
Datum(6,label_6,1)
Datum(11,label_11,1)
Datum(16,label_16,1)</b> 
  + And the new parquet file (/partitionKey=1/00089-422-de4dcfc2-0070-4e9d-a0d2-1c5aaa8255bd-00001.parquet) contains:
<b class=BLU>Datum(1,label_1X,1)</b> 
- should reading an updated table using merge-on-read
  + Given a table that has been updated 
  + When we read from it 
  + Then the table still contains 20 records 
  + And there are no new data files 
CopyOnWriteSpec:
A copy-on-write table
- should create no new files for copy-on-write
  + Given SQL:
<b class=BLU>'CREATE TABLE cow_table (id int,
label String,
partitionKey long) TBLPROPERTIES (
    'format-version' = '2',
    'write.delete.mode'='copy-on-write',
    'write.update.mode'='copy-on-write',
    'write.merge.mode'='copy-on-write'
) PARTITIONED BY (partitionKey); </b> 
  + When we execute it 
  + Then there is an Iceberg table, /tmp/SparkForTesting13151680448113525139/cow_table 
- should insert creates new files for copy-on-write
  + Given SQL:
INSERT INTO TABLE cow_table (id,
label,
partitionKey) VALUES (0, 'label_0', 0),
(1, 'label_1', 1),
(2, 'label_2', 2),
(3, 'label_3', 3),
(4, 'label_4', 4),
(5, 'label_5', 0),
(6, 'label_6', 1),
(7, 'label_7', 2),
(8, 'label_8', 3),
(9, 'label_9', 4),
(10, 'label_10', 0),
(11, 'label_11', 1),
(12, 'label_12', 2),
(13, 'label_13', 3),
(14, 'label_14', 4),
(15, 'label_15', 0),
(16, 'label_16', 1),
(17, 'label_17', 2),
(18, 'label_18', 3),
(19, 'label_19', 4) 
  + When we execute it 
  + Then there are now 10 data files:
<b class=BLU>/partitionKey=0/.00005-633-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet.crc
</b><b class=BLU>/partitionKey=0/00005-633-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet
</b><b class=BLU>/partitionKey=1/.00069-634-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet.crc
</b><b class=BLU>/partitionKey=1/00069-634-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet
</b><b class=BLU>/partitionKey=2/.00128-636-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet.crc
</b><b class=BLU>/partitionKey=2/00128-636-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet
</b><b class=BLU>/partitionKey=3/.00107-635-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet.crc
</b><b class=BLU>/partitionKey=3/00107-635-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet
</b><b class=BLU>/partitionKey=4/.00140-637-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet.crc
</b><b class=BLU>/partitionKey=4/00140-637-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet</b> 
  + And the table contains:
<b class=BLU>Datum(0,label_0,0)
Datum(1,label_1,1)
Datum(2,label_2,2)
Datum(3,label_3,3)
Datum(4,label_4,4)
Datum(5,label_5,0)
Datum(6,label_6,1)
Datum(7,label_7,2)
Datum(8,label_8,3)
Datum(9,label_9,4)
Datum(10,label_10,0)
Datum(11,label_11,1)
Datum(12,label_12,2)
Datum(13,label_13,3)
Datum(14,label_14,4)
Datum(15,label_15,0)
Datum(16,label_16,1)
Datum(17,label_17,2)
Datum(18,label_18,3)
Datum(19,label_19,4)</b> 
- should update creates no new files for copy-on-write
  + Given SQL:
UPDATE cow_table SET label='label_1X' WHERE id=1 
  + When we execute it 
  + Then there are now 12 data files:
<b class=GRN>/partitionKey=0/.00005-633-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet.crc
</b><b class=GRN>/partitionKey=0/00005-633-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet
</b><b class=GRN>/partitionKey=1/.00069-634-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet.crc
</b><b class=BLU>/partitionKey=1/.00178-836-d16c7f28-ab5a-402a-a953-0e120216f828-00001.parquet.crc
</b><b class=GRN>/partitionKey=1/00069-634-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet
</b><b class=BLU>/partitionKey=1/00178-836-d16c7f28-ab5a-402a-a953-0e120216f828-00001.parquet
</b><b class=GRN>/partitionKey=2/.00128-636-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet.crc
</b><b class=GRN>/partitionKey=2/00128-636-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet
</b><b class=GRN>/partitionKey=3/.00107-635-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet.crc
</b><b class=GRN>/partitionKey=3/00107-635-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet
</b><b class=GRN>/partitionKey=4/.00140-637-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet.crc
</b><b class=GRN>/partitionKey=4/00140-637-433192f6-fccb-402b-95dc-94b1e4114ffa-00001.parquet</b> 
  + And the deleted files are:
<b class=RED>e4114ffa-00001.parquet.crc
4114ffa-00001.parquet
e4114ffa-00001.parquet.crc
4114ffa-00001.parquet
e4114ffa-00001.parquet.crc
4114ffa-00001.parquet
e4114ffa-00001.parquet.crc
4114ffa-00001.parquet
e4114ffa-00001.parquet.crc
4114ffa-00001.parquet</b> 
  + And the table contains:
<b class=BLU>Datum(0,label_0,0)
Datum(1,label_1X,1)
Datum(2,label_2,2)
Datum(3,label_3,3)
Datum(4,label_4,4)
Datum(5,label_5,0)
Datum(6,label_6,1)
Datum(7,label_7,2)
Datum(8,label_8,3)
Datum(9,label_9,4)
Datum(10,label_10,0)
Datum(11,label_11,1)
Datum(12,label_12,2)
Datum(13,label_13,3)
Datum(14,label_14,4)
Datum(15,label_15,0)
Datum(16,label_16,1)
Datum(17,label_17,2)
Datum(18,label_18,3)
Datum(19,label_19,4)</b> 
  + And the new data file contains just the updated row(s) 
- should reading an updated table using copy-on-write
  + Given a table that has been updated 
  + When we read from it 
  + Then the table still contains 20 records 
  + And there are no new data files 
Run completed in 11 seconds, 151 milliseconds.
Total number of tests run: 13
Suites: completed 6, aborted 0
Tests: succeeded 13, failed 0, canceled 0, ignored 1, pending 0
All tests passed.
</pre>
</body>
</html>
